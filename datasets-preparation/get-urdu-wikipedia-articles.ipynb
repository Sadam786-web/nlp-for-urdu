{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from multiprocessing import Process, Value, Lock, Pool\n",
    "import gc\n",
    "PATH = '/home/anurag/practice/datasets/UrduWikipediaArticles/'\n",
    "mapping_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_urdu_wikipedia_links.pkl', 'rb') as f:\n",
    "    all_urls = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345069"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for counter, url in enumerate(all_urls):\n",
    "#     if counter < 3691:\n",
    "#         continue\n",
    "def parallel_fetch(offset,urls):\n",
    "    print(multiprocessing.current_process())\n",
    "    for counter,url in enumerate(urls):\n",
    "        html_doc = ''\n",
    "        try:\n",
    "            with urlopen(url) as response:\n",
    "                for line in response:\n",
    "                    line = line.decode('utf-8')\n",
    "                    html_doc = html_doc + line.replace('\\n','')\n",
    "            soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "            print(soup.title.string)\n",
    "            paras = soup.find_all('p')\n",
    "            article = ''\n",
    "            for para in paras:\n",
    "                article = article + para.text + '\\n'\n",
    "            article = re.sub(r'\\([^)]*\\)', r'', article)\n",
    "            article = re.sub(r'\\[[^\\]]*\\]', r'', article)\n",
    "            article = re.sub(r'<[^>]*>', r'', article)\n",
    "            article = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', article)\n",
    "            article = article.replace(u'\\ufeff','')\n",
    "            article = article.replace(u'\\xa0', u' ')\n",
    "            article = article.replace('  ', ' ');\n",
    "            article = article.replace(' , ', ', ');\n",
    "    #         devanagari_nums = ('०','१','२','३','४','५','६','७','८','९')\n",
    "    #         for c, n in enumerate(devanagari_nums):\n",
    "    #             article = re.sub(n, str(c), article)\n",
    "            filename = PATH + str(counter+offset) + '.pkl'\n",
    "#             mapping_dict[filename] = soup.title.string\n",
    "            with open(filename, 'wb') as f:\n",
    "                pickle.dump(article,f)\n",
    "            print(\"Saved \" + filename)\n",
    "            gc.collect()\n",
    "        except:\n",
    "            print('Failed')\n",
    "            continue\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done=0\n",
    "total_news = len(all_urls)\n",
    "cpus = multiprocessing.cpu_count()\n",
    "chunk_size = total_news//cpus\n",
    "procs = [Process(target=parallel_fetch, args=(cpu*chunk_size+done,all_urls[cpu*chunk_size+done:(cpu+1)*chunk_size]))for cpu in range(cpus)]\n",
    "\n",
    "for p in procs: p.start()\n",
    "for p in procs: p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
