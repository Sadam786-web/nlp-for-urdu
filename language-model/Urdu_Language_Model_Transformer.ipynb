{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IwVgTNGDoNoo"
   },
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1326,
     "status": "ok",
     "timestamp": 1555090802079,
     "user": {
      "displayName": "Anurag Singh",
      "photoUrl": "https://lh3.googleusercontent.com/-oZFveA_nC3o/AAAAAAAAAAI/AAAAAAAAAO0/S1uGDMOYRgk/s64/photo.jpg",
      "userId": "02138464107931395468"
     },
     "user_tz": -330
    },
    "id": "me1gujePoc6r",
    "outputId": "46b973c4-2ecf-4d17-b811-6f0b245cd212"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.57', '1.1.0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai, torch\n",
    "fastai.__version__ , torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "66hWLS6aooA1"
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/gaurav/PycharmProjects/nlp-for-urdu/language-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "86oUCOs2oqRo"
   },
   "outputs": [],
   "source": [
    "class UrduTokenizer(BaseTokenizer):\n",
    "    def __init__(self, lang:str):\n",
    "        self.lang = lang\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.Load(str(path/\"../tokenizer/urdu_lm.model\"))\n",
    "        \n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        return self.sp.EncodeAsPieces(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-fucar0ipS6h"
   },
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(path/\"../tokenizer/urdu_lm.model\"))\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(30000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "04tP6drWpWbt"
   },
   "outputs": [],
   "source": [
    "urdu_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P5DaVjxypYhH"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(tok_func=UrduTokenizer, lang='ur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 805,
     "status": "ok",
     "timestamp": 1555092031810,
     "user": {
      "displayName": "Anurag Singh",
      "photoUrl": "https://lh3.googleusercontent.com/-oZFveA_nC3o/AAAAAAAAAAI/AAAAAAAAAO0/S1uGDMOYRgk/s64/photo.jpg",
      "userId": "02138464107931395468"
     },
     "user_tz": -330
    },
    "id": "kLIHR42ApaRQ",
    "outputId": "b3e36d49-506d-4ccb-b984-93b48b68a83e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dHhiu_eipcwd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_folder(path=path/'transformer', tokenizer=tokenizer, vocab=urdu_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLqqPxW2pl8s"
   },
   "outputs": [],
   "source": [
    "data_lm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PkSlOJaypn3O"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>▁ xx bo s ▁ہر سٹ ، ▁الینوائے ▁ریاستہائے ▁متحدہ ▁امریکا ▁کا ▁ایک ▁شہر ▁جو ▁الینوائے ▁میں ▁واقع ▁ہے۔ ▁ہر سٹ ، ▁الینوائے ▁کی ▁مجموع ی ▁آبادی ▁80 5 ▁افراد ▁پر ▁مشتمل ▁ہے۔ ▁ xx bo s ▁مجلس ▁دستور ▁ساز ▁آئین ▁ہند ▁کی ▁تشکیل ▁کے ▁لیے ▁قائم ▁کی ▁گئی ▁تھی۔ برطانوی ▁سامراج ▁سے ▁بھارت ▁کی ▁آزادی ▁کے ▁بعد ▁مجلس ▁دستور ▁ساز ▁کے ▁ارکان ▁ہی ▁پہلی ▁پارلیمان ▁کے ▁ارکان ▁کے ▁طور</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>▁2 ▁اگست ▁1897 ء ▁تک ▁برطانوی ▁ہند ▁کے ▁صوبے ▁شمال ▁مشرقی ▁سرحدی ▁صوبے ▁کے ▁علاقے ▁مالاکنڈ ▁میں ▁برطانوی ▁افواج ▁کے ▁ایک ▁فوجی ▁کیمپ ▁کو ▁اس ▁وقت ▁مقامی ▁پشتون ▁جنگجوؤں ▁کی ▁جانب ▁سے ▁محاصرے ▁کا ▁سامنا ▁کرنا ▁پڑا ▁جب ▁ڈیورنڈ ▁لائن ▁کی ▁وجہ ▁سے ▁بہت ▁سے ▁پشتون وں ▁کی ▁زمین ▁دو ▁ملکوں ▁برطانوی ▁ہند ▁اور ▁افغانستان ▁کے ▁درمیان ▁منقسم ▁ہوکر ▁رہ ▁گئی۔ ▁اس ▁15 19 ▁میل ▁سرحدی ▁تقسیم ▁کو ▁افغان ▁انگریز</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>▁ہو ▁گئی ▁ہے ▁۔ ان ▁کے ▁علاوہ ▁مدارس ▁کے ▁طلبہ ▁کے ▁لیے ▁آسان ▁دینیات ▁ ، منصف ▁کے ▁مضامین ▁کا ▁مجموعہ ▁نقوش ▁م وع ظ ت ، ع صر ▁حاضر ▁کے ▁سماجی ▁مسائل ▁ ، دینی ▁و ▁عصری ▁تعلیم ▁: مس ائل ▁اور ▁حل ، ▁شمع ▁فرو ز اں ، ▁دعوت ی ▁و ▁تذکیر ی ▁انداز ▁کی ▁کتابیں ▁ہیں ▁ ۔آپ ▁کی ▁بقی ہ ▁کتابیں ▁حسب ▁ذیل ▁ہیں : راہ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>▁کی ▁مجموع ی ▁آبادی ▁13 ,108 ▁افراد ▁پر ▁مشتمل ▁ہے۔ ▁ xx bo s ▁ &lt;unk&gt; س راج ▁رئیس انی ▁کے ▁آخری ▁الفاظ ▁میر ▁سراج ▁خان ▁رئیس انی ▁ایک ▁پاکستانی ▁سیاست ▁دان ▁جن ▁کا ▁تعلق ▁بلوچستان ▁عوامی ▁پارٹی ▁سے ▁تھا۔ ▁وہ ▁13 ▁جولائی ▁2018 ء ▁کو ▁پاکستانی ▁عام ▁انتخابات ▁سے ▁قبل ▁اپنی ▁نشست ▁کے ▁لیے ▁مہم ▁چلا ▁رہے ▁تھے ▁اور ▁مہم ▁کے ▁دوران ▁خودکش ▁دھماکا ▁ہو ▁گیا ▁اور ▁فوت ▁ہو</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>▁خان &lt;unk&gt; ro z &lt;unk&gt; ▁نواب ▁خیر ▁بخش ▁مری ▁ &lt;unk&gt; ▁میر ▁بالا چ ▁مری ▁ &lt;unk&gt; ▁bra ham d agh &lt;unk&gt; g ti اللہ ▁نذر ▁بلوچ &lt;unk&gt; ja ved &lt;unk&gt; gal &lt;unk&gt; d &lt;unk&gt; ▁ &lt;unk&gt; عبد ال مالک ▁ریگ ی ▁ &lt;unk&gt; a b d ol ham id &lt;unk&gt; ▁r ig i ▁ &lt;unk&gt; ▁پاکستان ▁چین ▁بی ▁ایل ▁اے : ▁10,000 &lt;unk&gt; i ▁s ecurity ▁force s 1973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Ga3phL0prUp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lm.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, TransformerXL, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): TransformerXL(\n",
       "    (encoder): Embedding(30000, 410)\n",
       "    (pos_enc): PositionalEncoding()\n",
       "    (drop_emb): Dropout(p=0.1)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=410, out_features=30000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.850728</td>\n",
       "      <td>4.848382</td>\n",
       "      <td>0.281403</td>\n",
       "      <td>32:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.303591</td>\n",
       "      <td>4.183890</td>\n",
       "      <td>0.341596</td>\n",
       "      <td>32:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.806851</td>\n",
       "      <td>3.737065</td>\n",
       "      <td>0.384724</td>\n",
       "      <td>32:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.692465</td>\n",
       "      <td>3.591967</td>\n",
       "      <td>0.393845</td>\n",
       "      <td>33:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.612472</td>\n",
       "      <td>3.553266</td>\n",
       "      <td>0.391731</td>\n",
       "      <td>34:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.610477</td>\n",
       "      <td>3.491082</td>\n",
       "      <td>0.396225</td>\n",
       "      <td>33:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.450806</td>\n",
       "      <td>3.401724</td>\n",
       "      <td>0.405535</td>\n",
       "      <td>32:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.453166</td>\n",
       "      <td>3.316013</td>\n",
       "      <td>0.413973</td>\n",
       "      <td>32:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.293946</td>\n",
       "      <td>3.237870</td>\n",
       "      <td>0.424381</td>\n",
       "      <td>32:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.179446</td>\n",
       "      <td>3.137322</td>\n",
       "      <td>0.437013</td>\n",
       "      <td>45:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.179914</td>\n",
       "      <td>3.049748</td>\n",
       "      <td>0.448241</td>\n",
       "      <td>32:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.154236</td>\n",
       "      <td>2.963731</td>\n",
       "      <td>0.461090</td>\n",
       "      <td>32:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.970814</td>\n",
       "      <td>2.873009</td>\n",
       "      <td>0.474892</td>\n",
       "      <td>32:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.811598</td>\n",
       "      <td>2.785454</td>\n",
       "      <td>0.488772</td>\n",
       "      <td>32:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.762010</td>\n",
       "      <td>2.705129</td>\n",
       "      <td>0.502535</td>\n",
       "      <td>32:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.649796</td>\n",
       "      <td>2.642635</td>\n",
       "      <td>0.513550</td>\n",
       "      <td>32:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.690373</td>\n",
       "      <td>2.591932</td>\n",
       "      <td>0.522441</td>\n",
       "      <td>32:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.606081</td>\n",
       "      <td>2.556429</td>\n",
       "      <td>0.528977</td>\n",
       "      <td>32:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.545823</td>\n",
       "      <td>2.541434</td>\n",
       "      <td>0.531832</td>\n",
       "      <td>32:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.318890</td>\n",
       "      <td>2.538687</td>\n",
       "      <td>0.532282</td>\n",
       "      <td>32:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.2814030647277832.\n",
      "Better model found at epoch 1 with accuracy value: 0.3415956497192383.\n",
      "Better model found at epoch 2 with accuracy value: 0.38472414016723633.\n",
      "Better model found at epoch 3 with accuracy value: 0.3938453495502472.\n",
      "Better model found at epoch 5 with accuracy value: 0.3962252736091614.\n",
      "Better model found at epoch 6 with accuracy value: 0.4055348336696625.\n",
      "Better model found at epoch 7 with accuracy value: 0.4139733910560608.\n",
      "Better model found at epoch 8 with accuracy value: 0.42438119649887085.\n",
      "Better model found at epoch 9 with accuracy value: 0.4370129406452179.\n",
      "Better model found at epoch 10 with accuracy value: 0.44824138283729553.\n",
      "Better model found at epoch 11 with accuracy value: 0.4610903263092041.\n",
      "Better model found at epoch 12 with accuracy value: 0.47489243745803833.\n",
      "Better model found at epoch 13 with accuracy value: 0.4887722134590149.\n",
      "Better model found at epoch 14 with accuracy value: 0.5025349259376526.\n",
      "Better model found at epoch 15 with accuracy value: 0.5135495662689209.\n",
      "Better model found at epoch 16 with accuracy value: 0.5224408507347107.\n",
      "Better model found at epoch 17 with accuracy value: 0.5289770364761353.\n",
      "Better model found at epoch 18 with accuracy value: 0.5318323969841003.\n",
      "Better model found at epoch 19 with accuracy value: 0.532281756401062.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(20, 1e-3, callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='model')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"میں کروں گا\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "میں کروں گا ، ▁آم وں ▁گا ▁بھارت ▁کا ▁ایک ▁آباد ▁مقام ▁جو ▁نا ,332 - ▁نواح ▁میں ▁واقع ▁ہے۔ ▁میں ▁کر وں ▁گا ، ▁آم وں ▁گا ▁کی ▁مجموع ی ▁آبادی ▁20 ,267 ▁افراد ▁پر ▁مشتمل ▁ہے۔ ▁ xx bo s ▁\n",
      "میں کروں گا ▁ریلوے ▁اسٹیشن ، ▁بھارت ▁میں ▁واقع ▁ہے۔ ▁سانچہ : بھارت ▁کے ▁ریلوے ▁اسٹیشن ▁ xx bo s ▁سینٹ - گرمین - دے - ٹاگ ے ▁متناسقات : ▁48 ▁g ▁سرخی وں ▁میں ▁ہوجائے ▁گا ▁اور ▁انکی ▁مدد ▁سے ▁کوئی ▁جنین\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.9) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.55350613666823"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(2.53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cpu')\n",
    "learn.model.eval()\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating embedding vectors for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/gaurav/PycharmProjects/nlp-for-urdu/language-model')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaults.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = load_learner(path / 'UrduDataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_model(learn.model)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30000, 410])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = encoder.state_dict()['encoder.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>400</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "      <th>406</th>\n",
       "      <th>407</th>\n",
       "      <th>408</th>\n",
       "      <th>409</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.274557</td>\n",
       "      <td>-0.066753</td>\n",
       "      <td>-0.156818</td>\n",
       "      <td>-0.158754</td>\n",
       "      <td>-0.255069</td>\n",
       "      <td>0.056576</td>\n",
       "      <td>0.053431</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>-0.055425</td>\n",
       "      <td>0.088921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266454</td>\n",
       "      <td>-0.199348</td>\n",
       "      <td>0.143059</td>\n",
       "      <td>-0.254380</td>\n",
       "      <td>0.039857</td>\n",
       "      <td>-0.223381</td>\n",
       "      <td>-0.148715</td>\n",
       "      <td>0.528780</td>\n",
       "      <td>0.363054</td>\n",
       "      <td>0.355241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.146572</td>\n",
       "      <td>-0.211287</td>\n",
       "      <td>0.088975</td>\n",
       "      <td>-0.141767</td>\n",
       "      <td>-0.108718</td>\n",
       "      <td>-0.089599</td>\n",
       "      <td>-0.023805</td>\n",
       "      <td>-0.106310</td>\n",
       "      <td>-0.146211</td>\n",
       "      <td>-0.033887</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106202</td>\n",
       "      <td>-0.031656</td>\n",
       "      <td>0.130010</td>\n",
       "      <td>-0.141824</td>\n",
       "      <td>-0.081605</td>\n",
       "      <td>-0.204387</td>\n",
       "      <td>-0.078683</td>\n",
       "      <td>0.149594</td>\n",
       "      <td>0.238998</td>\n",
       "      <td>0.068903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.143155</td>\n",
       "      <td>-0.212103</td>\n",
       "      <td>0.087519</td>\n",
       "      <td>-0.136676</td>\n",
       "      <td>-0.105588</td>\n",
       "      <td>-0.087899</td>\n",
       "      <td>-0.021834</td>\n",
       "      <td>-0.109260</td>\n",
       "      <td>-0.135154</td>\n",
       "      <td>-0.034089</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108604</td>\n",
       "      <td>-0.031469</td>\n",
       "      <td>0.132030</td>\n",
       "      <td>-0.141408</td>\n",
       "      <td>-0.080047</td>\n",
       "      <td>-0.202075</td>\n",
       "      <td>-0.081220</td>\n",
       "      <td>0.143720</td>\n",
       "      <td>0.238397</td>\n",
       "      <td>0.061986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.211712</td>\n",
       "      <td>0.308071</td>\n",
       "      <td>0.177578</td>\n",
       "      <td>0.125462</td>\n",
       "      <td>0.030023</td>\n",
       "      <td>-0.147874</td>\n",
       "      <td>0.096243</td>\n",
       "      <td>0.123668</td>\n",
       "      <td>-0.426578</td>\n",
       "      <td>-0.094092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229549</td>\n",
       "      <td>0.111376</td>\n",
       "      <td>0.169151</td>\n",
       "      <td>0.060326</td>\n",
       "      <td>-0.007837</td>\n",
       "      <td>0.019716</td>\n",
       "      <td>-0.110968</td>\n",
       "      <td>0.253889</td>\n",
       "      <td>-0.249155</td>\n",
       "      <td>-0.279694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.093593</td>\n",
       "      <td>0.164756</td>\n",
       "      <td>-0.161624</td>\n",
       "      <td>0.118464</td>\n",
       "      <td>-0.319576</td>\n",
       "      <td>0.171257</td>\n",
       "      <td>0.381318</td>\n",
       "      <td>-0.067512</td>\n",
       "      <td>-0.110809</td>\n",
       "      <td>0.196707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057503</td>\n",
       "      <td>0.078691</td>\n",
       "      <td>0.149484</td>\n",
       "      <td>-0.027757</td>\n",
       "      <td>-0.124158</td>\n",
       "      <td>-0.158895</td>\n",
       "      <td>-0.327782</td>\n",
       "      <td>-0.105953</td>\n",
       "      <td>-0.139209</td>\n",
       "      <td>-0.369162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.274557 -0.066753 -0.156818 -0.158754 -0.255069  0.056576  0.053431   \n",
       "1  0.146572 -0.211287  0.088975 -0.141767 -0.108718 -0.089599 -0.023805   \n",
       "2  0.143155 -0.212103  0.087519 -0.136676 -0.105588 -0.087899 -0.021834   \n",
       "3  0.211712  0.308071  0.177578  0.125462  0.030023 -0.147874  0.096243   \n",
       "4 -0.093593  0.164756 -0.161624  0.118464 -0.319576  0.171257  0.381318   \n",
       "\n",
       "        7         8         9    ...       400       401       402       403  \\\n",
       "0  0.010714 -0.055425  0.088921  ...  0.266454 -0.199348  0.143059 -0.254380   \n",
       "1 -0.106310 -0.146211 -0.033887  ... -0.106202 -0.031656  0.130010 -0.141824   \n",
       "2 -0.109260 -0.135154 -0.034089  ... -0.108604 -0.031469  0.132030 -0.141408   \n",
       "3  0.123668 -0.426578 -0.094092  ...  0.229549  0.111376  0.169151  0.060326   \n",
       "4 -0.067512 -0.110809  0.196707  ...  0.057503  0.078691  0.149484 -0.027757   \n",
       "\n",
       "        404       405       406       407       408       409  \n",
       "0  0.039857 -0.223381 -0.148715  0.528780  0.363054  0.355241  \n",
       "1 -0.081605 -0.204387 -0.078683  0.149594  0.238998  0.068903  \n",
       "2 -0.080047 -0.202075 -0.081220  0.143720  0.238397  0.061986  \n",
       "3 -0.007837  0.019716 -0.110968  0.253889 -0.249155 -0.279694  \n",
       "4 -0.124158 -0.158895 -0.327782 -0.105953 -0.139209 -0.369162  \n",
       "\n",
       "[5 rows x 410 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 410)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('embeddings_transformer.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>▁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>▁کے</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  <unk>\n",
       "1    <s>\n",
       "2   </s>\n",
       "3      ▁\n",
       "4    ▁کے"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('embeddings_transformer_metadata.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1466, -0.2113,  0.0890, -0.1418, -0.1087, -0.0896, -0.0238, -0.1063,\n",
       "        -0.1462, -0.0339, -0.1137,  0.0758,  0.0282,  0.0093,  0.0273,  0.1846,\n",
       "         0.0425,  0.0837,  0.0428, -0.0909,  0.0373,  0.0754,  0.0702,  0.0277,\n",
       "         0.0829, -0.0511, -0.0516, -0.1251, -0.0317,  0.2091,  0.0412, -0.1283,\n",
       "         0.0293, -0.0450,  0.1177, -0.0839, -0.0771,  0.1631, -0.0322, -0.2058,\n",
       "        -0.1828, -0.0136,  0.1263, -0.0554,  0.0994, -0.0014, -0.0203,  0.0995,\n",
       "         0.0246, -0.0039,  0.0406, -0.0652, -0.1839, -0.1206, -0.1233,  0.0488,\n",
       "         0.0199, -0.0707, -0.0410,  0.0083, -0.0793, -0.0641, -0.0422,  0.0103,\n",
       "         0.1412, -0.0111,  0.0932, -0.1345, -0.0015, -0.0886,  0.1883,  0.1094,\n",
       "         0.0177, -0.1486, -0.0350, -0.0388, -0.0448,  0.0604, -0.1848, -0.0791,\n",
       "        -0.0317, -0.0367,  0.0415, -0.1847,  0.0167, -0.0286,  0.1326, -0.0165,\n",
       "         0.0839, -0.1350,  0.0856, -0.1036,  0.0738,  0.0462, -0.1167, -0.0187,\n",
       "        -0.0811,  0.1136,  0.1478,  0.1480, -0.0395,  0.1085,  0.1593,  0.0106,\n",
       "         0.0308, -0.0685, -0.1098,  0.1017, -0.0840, -0.1348,  0.0102, -0.0771,\n",
       "        -0.0861, -0.1514, -0.0383,  0.0864, -0.0655,  0.0945, -0.0474,  0.2546,\n",
       "        -0.1657,  0.0737,  0.2150,  0.1245,  0.0718, -0.2334, -0.0335, -0.1275,\n",
       "        -0.0244, -0.0088, -0.0525,  0.0887,  0.1024, -0.0352,  0.0109,  0.0820,\n",
       "         0.3529,  0.1752,  0.1057, -0.0872, -0.0373, -0.0867, -0.0769, -0.0176,\n",
       "         0.1095, -0.0280, -0.1559, -0.1139,  0.1087, -0.1041, -0.1221,  0.0350,\n",
       "        -0.0721,  0.0073,  0.0005,  0.1147,  0.0302, -0.1055, -0.0605, -0.0457,\n",
       "        -0.0998,  0.0272,  0.0372, -0.2382, -0.0960,  0.0324, -0.1040, -0.0794,\n",
       "        -0.1424,  0.0247, -0.0889,  0.1289, -0.0151, -0.1339,  0.0601, -0.1192,\n",
       "        -0.0890,  0.0393, -0.0641,  0.0534,  0.0426,  0.0775, -0.0256, -0.0494,\n",
       "         0.0176, -0.0618, -0.0509,  0.0981,  0.1817,  0.0568,  0.0746, -0.0735,\n",
       "        -0.0207, -0.1001, -0.1978, -0.0995, -0.0902,  0.0206, -0.2056, -0.0846,\n",
       "         0.0028, -0.0143, -0.0278, -0.0765, -0.2742, -0.0046, -0.1852, -0.0305,\n",
       "         0.1418,  0.1404, -0.0923, -0.1769, -0.0275, -0.2072,  0.1001, -0.0615,\n",
       "         0.0812, -0.0665,  0.1493,  0.1306,  0.0375, -0.0079,  0.0976, -0.0410,\n",
       "        -0.0091, -0.1707, -0.0901, -0.1555, -0.0471, -0.1972, -0.1454,  0.2318,\n",
       "         0.0544, -0.0538, -0.0215, -0.1186, -0.1924,  0.0019,  0.0445, -0.0356,\n",
       "        -0.1196, -0.0465, -0.0774,  0.1284,  0.0880, -0.0088, -0.0277,  0.0592,\n",
       "        -0.2327,  0.0332, -0.0456, -0.1314,  0.2787,  0.0322,  0.1615,  0.0318,\n",
       "         0.0174, -0.1815,  0.1241, -0.0057, -0.0485, -0.0165, -0.0301,  0.0894,\n",
       "         0.0155, -0.1222, -0.1057,  0.1498, -0.0945,  0.0445, -0.0314,  0.1498,\n",
       "        -0.0180,  0.0121, -0.0270,  0.0783, -0.0447, -0.0690,  0.0263,  0.0532,\n",
       "        -0.1436,  0.0940,  0.0013,  0.0478,  0.1757, -0.0560,  0.0039,  0.0048,\n",
       "        -0.1669, -0.0783, -0.0403, -0.0896,  0.0411,  0.1890, -0.0205,  0.0518,\n",
       "         0.1323, -0.1092,  0.0940, -0.1578,  0.0081,  0.0401,  0.0562, -0.0501,\n",
       "         0.0857,  0.1567,  0.0223, -0.0563, -0.1184, -0.0378, -0.1039, -0.0727,\n",
       "        -0.0363,  0.0202, -0.1302, -0.0920,  0.0714, -0.0205,  0.0708,  0.0441,\n",
       "        -0.1370, -0.1532,  0.1258, -0.1904,  0.1346, -0.0652, -0.1520, -0.0662,\n",
       "        -0.0304,  0.0571,  0.0900,  0.0645, -0.0746,  0.0435, -0.0393,  0.0518,\n",
       "         0.0363,  0.1765, -0.0901, -0.0244,  0.0533,  0.1425,  0.0456, -0.0577,\n",
       "        -0.0717,  0.0193,  0.1415, -0.1274,  0.0697,  0.0725,  0.0732,  0.1036,\n",
       "        -0.0541,  0.2066,  0.0935, -0.0273, -0.1624,  0.1453, -0.0819, -0.0489,\n",
       "        -0.0228, -0.0641,  0.0587,  0.1151,  0.1705, -0.1114, -0.0984,  0.0577,\n",
       "         0.0232, -0.1428,  0.2165,  0.0375,  0.1500, -0.1330,  0.0705,  0.0737,\n",
       "        -0.0091,  0.0547, -0.0612, -0.1119, -0.1595,  0.0016,  0.1184, -0.1735,\n",
       "        -0.0548, -0.0362,  0.0275,  0.0161,  0.1032,  0.0065,  0.1067, -0.0399,\n",
       "        -0.0147, -0.0111,  0.0781, -0.0551, -0.0690, -0.0708, -0.0348,  0.0441,\n",
       "        -0.1062, -0.0317,  0.1300, -0.1418, -0.0816, -0.2044, -0.0787,  0.1496,\n",
       "         0.2390,  0.0689], device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Urdu_Language_Model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
